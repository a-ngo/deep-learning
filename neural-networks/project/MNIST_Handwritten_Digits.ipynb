{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, you will build a neural network of your own design to evaluate the MNIST dataset.\n",
    "\n",
    "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](http://yann.lecun.com/exdb/mnist/) and include:\n",
    "\n",
    "88% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "95.3% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "\n",
    "MNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Specify your transforms as a list if you intend to .\n",
    "The transforms module is already loaded as `transforms`.\n",
    "\n",
    "MNIST is fortunately included in the torchvision module.\n",
    "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
    "Make sure to specify `download=True`! \n",
    "\n",
    "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Define transforms\n",
    "\n",
    "# use .Compose to combine multiple transforms together\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create training set and define training dataloader\n",
    "training_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "training_data_loader = torch.utils.data.DataLoader(training_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "# Create test set and define test dataloader\n",
    "test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=batch_size)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your preprocessing\n",
    "\n",
    "In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transformed the images to tensors -> for better performance processing the images\n",
    "- and normalized the images -> hoping to achieve better training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
    "\n",
    "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
    "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
    "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
    "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\n",
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "    \n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features size = torch.Size([64, 1, 28, 28])\n",
      "labels size = torch.Size([64])\n",
      "tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]]]) tensor([9, 7, 7, 1, 8, 7, 7, 4, 7, 1, 6, 6, 4, 7, 1, 1, 8, 9, 1, 6, 5, 1, 3, 3,\n",
      "        1, 2, 2, 5, 4, 9, 6, 5, 7, 2, 5, 7, 7, 2, 6, 4, 8, 8, 0, 6, 2, 6, 8, 5,\n",
      "        7, 0, 6, 5, 9, 4, 2, 2, 0, 9, 3, 8, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# Explore data\n",
    "# show5(training_data_loader)\n",
    "# show5(test_data_loader)\n",
    "\n",
    "# Print training data\n",
    "datatiter = iter(training_data_loader)\n",
    "data = next(datatiter)\n",
    "features, labels = data\n",
    "\n",
    "print(f\"features size = {features.size()}\")\n",
    "print(f\"labels size = {labels.size()}\")\n",
    "print(features, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
    "Use any architecture you like. \n",
    "\n",
    "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore data and check sizes\n",
    "# TODO: define model architecture and set correct tensor sizes\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu\n",
    "        self.fc1 = nn.Linear(64 * 64 * 3, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 5, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        \n",
    "       # RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x784 and 64x256)\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(6400, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 84),\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(84, 10)\n",
    "        self.fc2 = nn.Softmax(dim=1) # added softmax per reviewer recommendation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.cnn1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.linear1(x))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a loss function and an optimizer, and instantiate the model.\n",
    "\n",
    "If you use a less common loss function, please note why you chose that loss function in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "# net = Net()\n",
    "net = CNN()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "\n",
    "# Choose an optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Choose a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running your Neural Network\n",
    "Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch. \n",
    "Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n",
    "\n",
    "If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train accuracy: 98.97% train loss: 1.47146\n",
      "Epoch 1 val accuracy: 98.37% val loss: 1.47725\n",
      "Epoch 2 train accuracy: 98.92% train loss: 1.47202\n",
      "Epoch 2 val accuracy: 98.71% val loss: 1.47386\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/anthony/workspace/deep-learning/neural-networks/project/MNIST_Handwritten_Digits.ipynb Cell 15\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anthony/workspace/deep-learning/neural-networks/project/MNIST_Handwritten_Digits.ipynb#X20sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anthony/workspace/deep-learning/neural-networks/project/MNIST_Handwritten_Digits.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anthony/workspace/deep-learning/neural-networks/project/MNIST_Handwritten_Digits.ipynb#X20sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anthony/workspace/deep-learning/neural-networks/project/MNIST_Handwritten_Digits.ipynb#X20sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anthony/workspace/deep-learning/neural-networks/project/MNIST_Handwritten_Digits.ipynb#X20sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: \n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# # Establish a list for our history\n",
    "# train_loss_history = list()\n",
    "# val_loss_history = list()\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     # net.train() # TODO: needed?\n",
    "#     train_loss = 0.0\n",
    "#     train_correct = 0\n",
    "#     for i, data in enumerate(training_data_loader):\n",
    "#         # data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "\n",
    "#         # Pass to GPU if available.\n",
    "#         # TODO: ok for mac?\n",
    "#         if torch.cuda.is_available():\n",
    "#             inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "#         optimizer.zero_grad() # TODO: needed?\n",
    "\n",
    "#         # TODO: grasp this\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "\n",
    "#         # TODO: grasp this - accuracy caluclation correct?\n",
    "#         _, preds =  torch.max(outputs.data, 1)\n",
    "#         train_correct += (preds == labels).sum().item()\n",
    "#         train_loss += loss.item()\n",
    "#     print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(training_data_loader):.2f}% training loss: {train_loss/len(training_data_loader):.5f}')\n",
    "#     train_loss_history.append(train_loss/len(training_data_loader))\n",
    "\n",
    "\n",
    "#     val_loss = 0.0\n",
    "#     val_correct = 0\n",
    "#     # net.eval() # TODO: needed?\n",
    "#     for inputs, labels in test_data_loader:\n",
    "#         # Pass to GPU if available.\n",
    "#         if torch.cuda.is_available():\n",
    "#             inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "#         # TODO: grasp this - accuracy caluclation correct?\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         _, preds = torch.max(outputs.data, 1)\n",
    "#         val_correct += (preds == labels).sum().item()\n",
    "#         val_loss += loss.item()\n",
    "#     print(f'Epoch {epoch + 1} validation accuracy: {val_correct/len(test_data_loader):.2f}% validation loss: {val_loss/len(test_data_loader):.5f}')\n",
    "#     val_loss_history.append(val_loss/len(test_data_loader))\n",
    "\n",
    "\n",
    "# TODO: difference in the accuracy calculation?\n",
    "\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_accuracy = []\n",
    "    for i, (inputs, labels) in enumerate(training_data_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_accuracy.append((preds == labels).sum().item() / preds.size(0) * 100)\n",
    "        \n",
    "    train_accuracy_calc = np.mean(train_accuracy)\n",
    "    train_loss_calc = train_loss/len(training_data_loader)\n",
    "    train_loss_history.append(np.mean(train_loss)/len(training_data_loader))\n",
    "    \n",
    "    print(f'Epoch {epoch + 1} train accuracy: {train_accuracy_calc:.2f}% train loss: {train_loss_calc:.5f}') \n",
    "    \n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_accuracy = []\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_data_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "        outputs = net(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "        val_accuracy.append((preds == labels).sum().item() / preds.size(0) * 100)\n",
    "        \n",
    "    val_accuracy_calc = np.mean(val_accuracy)\n",
    "    val_loss_calc = val_loss/len(test_data_loader)\n",
    "    val_loss_history.append(np.mean(val_loss)/len(test_data_loader))\n",
    "    \n",
    "    print(f'Epoch {epoch + 1} val accuracy: {val_accuracy_calc:.2f}% val loss: {val_loss_calc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss (and validation loss/accuracy, if recorded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_history, label=\"Training Loss\")\n",
    "plt.plot(val_loss_history, label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model\n",
    "Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction. \n",
    "\n",
    "If your accuracy is over 90%, great work, but see if you can push a bit further! \n",
    "If your accuracy is under 90%, you'll need to make improvements.\n",
    "Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model\n",
    "\n",
    "Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your model\n",
    "Using `torch.save`, save your model for future loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,'MNIST_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
